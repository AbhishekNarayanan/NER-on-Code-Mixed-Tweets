{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP PROJECT FOR UE16CS333 BY TEAM 13\n",
    "## Team Members :\n",
    "## Abhishek Narayanan (01FB16ECS016)\n",
    "## Abhishek Prasad (01FB16ECS017)\n",
    "## Abijna Rao (01FB16ECS019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model Using Decision Tree Classifier, Naive Bayes Classifier And Random Forest Classifier\n",
    "\n",
    "### This notebok compares our approach with the baseline models of the aforementioned reserach paper cited\n",
    "### The ensemble learner is our added novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading feature vectors along with tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+1:word', '+1:word.1stUpper()', '+1:word.isAlpha()', '+1:word.isdigit()', '+1:word.istitle()', '+1:word.isupper()', '+1:word.lower()', '+1:word.startsWith#()', '+1:word.startsWith@()', 'BOS', '-1:word', '-1:word.1stUpper()', '-1:word.isAlpha()', '-1:word.isdigit()', '-1:word.istitle()', '-1:word.isupper()', '-1:word.lower()', '-1:word.startsWith#()', '-1:word.startsWith@()', 'EOS', 'bias', 'word', 'word.1stUpper()', 'word.isAlpha()', 'word.isdigit()', 'word.istitle()', 'word.isupper()', 'word.lower()', 'word.startsWith#()', 'word.startsWith@()', 'word[-2:]', 'word[-3:]', 'word.Tag']\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('Twitterdata/featureVectors.csv')\n",
    "print(list(X))\n",
    "y = X['word.Tag']\n",
    "\n",
    "# removing the Tag column from X to keep it as feature only.\n",
    "X.drop('word.Tag', axis=1, inplace=True)\n",
    "\n",
    "# handelling the NaN and inf values in the dataset\n",
    "X=X.astype('float32')\n",
    "y=y.astype('float32')\n",
    "X = np.nan_to_num(X)\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision tree..\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.17      0.20      0.18        10\n",
      "       B-Org       0.50      0.57      0.53       350\n",
      "       I-Per       0.32      0.35      0.33       153\n",
      "       Other       0.97      0.96      0.97     16653\n",
      "       B-Per       0.61      0.60      0.60       645\n",
      "       I-Org       0.33      0.26      0.29        23\n",
      "       B-Loc       0.42      0.47      0.45       202\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     18036\n",
      "   macro avg       0.47      0.49      0.48     18036\n",
      "weighted avg       0.93      0.93      0.93     18036\n",
      "\n",
      "Decision Tree F1 score: 0.9301\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=32, class_weight=\"balanced\")#[{0:1,1:1}, {0:1,1:50}, {0:1,1:18},{0:1,1:1940}, {0:1,1:70},{0:1,1:3},{0:1,1:25}])\n",
    "\n",
    "# fit\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = dtc.predict(X_test)\n",
    "target_names = ['I-Loc', 'B-Org', 'I-Per', 'Other', 'B-Per', 'I-Org', 'B-Loc']\n",
    "\n",
    "# print\n",
    "print (\"Results for Decision tree..\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print (\"Decision Tree F1 score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Naive Bayes...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.01      0.20      0.03        10\n",
      "       B-Org       0.16      0.20      0.18       350\n",
      "       I-Per       0.05      0.15      0.08       153\n",
      "       Other       0.97      0.78      0.86     16653\n",
      "       B-Per       0.27      0.45      0.34       645\n",
      "       I-Org       0.00      0.35      0.01        23\n",
      "       B-Loc       0.06      0.26      0.09       202\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     18036\n",
      "   macro avg       0.22      0.34      0.23     18036\n",
      "weighted avg       0.91      0.74      0.81     18036\n",
      "\n",
      "Naive Bayes F1 score: 0.6685\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print (\"Results for Naive Bayes...\")\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print (\"Naive Bayes F1 score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.00      0.00      0.00        10\n",
      "       B-Org       0.85      0.13      0.23       350\n",
      "       I-Per       0.67      0.03      0.05       153\n",
      "       Other       0.94      1.00      0.97     16653\n",
      "       B-Per       0.79      0.36      0.50       645\n",
      "       I-Org       0.00      0.00      0.00        23\n",
      "       B-Loc       0.00      0.00      0.00       202\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     18036\n",
      "   macro avg       0.46      0.22      0.25     18036\n",
      "weighted avg       0.92      0.94      0.92     18036\n",
      "\n",
      "random Forest F1 score: 0.9569\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"Results for Random Forest...\")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print (\"random Forest F1 score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.00      0.00      0.00        10\n",
      "       B-Org       0.96      0.26      0.41       350\n",
      "       I-Per       0.80      0.03      0.05       153\n",
      "       Other       0.94      1.00      0.97     16653\n",
      "       B-Per       0.82      0.38      0.52       645\n",
      "       I-Org       0.00      0.00      0.00        23\n",
      "       B-Loc       1.00      0.02      0.04       202\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     18036\n",
      "   macro avg       0.65      0.24      0.28     18036\n",
      "weighted avg       0.94      0.94      0.92     18036\n",
      "\n",
      "Ensemble Model F1 score: 0.9583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#create a dictionary of our models\n",
    "estimators=[('decision_tree', dtc), ('naive_bayes', gnb), ('random_forest', clf)]\n",
    "\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print (\"Results for Random Forest...\")\n",
    "#test our model on the test data\n",
    "y_predict = ensemble.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print (\"Ensemble Model F1 score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
